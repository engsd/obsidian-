#### [故事] 一个用于评估罪犯再犯风险的算法，被发现在种族上存在系统性偏见。这是如何发生的？是数据的历史偏见，还是模型设计的缺陷？


#### [谜题] 如何定义算法的“公平”？有“统计均等”、“机会均等”等多种数学定义，但它们彼此冲突时，我们该如何选择？这个选择本身是一种技术决策还是伦理决策？


#### [影响] 算法的“黑箱”特性如何加剧了问责的困难？当算法决策出错时，谁应该负责？是开发者、公司、用户还是算法本身？


## 摘要


## 要点

- 
- 
- 

## 链接

- [[{h3_subfolder} MOC]]
